{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torchvision\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class UTKFaceDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.labels_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,self.labels_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        labels = self.labels_frame.iloc[idx, 1:].as_matrix()\n",
    "        labels = labels.astype('float')#.reshape(-1, 2)\n",
    "        image = np.asarray(image)/255\n",
    "        sample = {'image': image, 'labels': labels, 'name': img_name}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "\n",
    "        return sample\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, labels = sample['image'], sample['labels']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'labels': torch.from_numpy(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = UTKFaceDataset(csv_file='UTKfacesaligngender.csv',\n",
    "                        root_dir='alignedimgs/',\n",
    "                        transform=transforms.Compose([ToTensor()]))\n",
    "\n",
    "datasetB = UTKFaceDataset(csv_file='UTKfacesaligngenderB.csv',\n",
    "                        root_dir='alignedimgs/',\n",
    "                        transform=transforms.Compose([ToTensor()]))\n",
    "#print(dataset[0])\n",
    "for i in range(len(dataset)):\n",
    "    sample = dataset[i]\n",
    "\n",
    "    print(i, sample['image'].size(), sample['labels'].size())\n",
    "\n",
    "    if i == 3:\n",
    "        break\n",
    "\n",
    "batch_size = 50\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = torch.utils.data.sampler.SubsetRandomSampler(train_indices)\n",
    "valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(datasetB, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)\n",
    "\n",
    "print(len(train_loader)*batch_size)\n",
    "print(len(validation_loader)*batch_size)\n",
    "def show_landmarks_batch(sample_batched):\n",
    "    images_batch, labels_batch = \\\n",
    "            sample_batched['image'], sample_batched['labels']\n",
    "    batch_size = len(images_batch)\n",
    "    im_size = images_batch.size(2)\n",
    "    print(\"labels \", sample_batched['labels'])\n",
    "    grid = utils.make_grid(images_batch)\n",
    "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "\n",
    "doShow = False\n",
    "if doShow:\n",
    "    for i_batch, sample_batched in enumerate(train_loader):\n",
    "        print(i_batch, sample_batched['image'].size(),\n",
    "              sample_batched['labels'].size())\n",
    "\n",
    "        # observe 4th batch and stop.\n",
    "        if i_batch == 3:\n",
    "            plt.figure()\n",
    "            show_landmarks_batch(sample_batched)\n",
    "            plt.axis('off')\n",
    "            plt.ioff()\n",
    "            plt.show()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Convolutional neural network (two convolutional layers)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=7, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(3*3*384, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5))\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5))\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(512, 2),\n",
    "            nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        out = self.layer1(x)\n",
    "        #print(out.shape)\n",
    "        out = self.layer2(out)\n",
    "        #print(out.shape)\n",
    "        out = self.layer3(out)\n",
    "        #print(out.shape)\n",
    "        out = F.interpolate(out, size=(3, 3), mode='bilinear')\n",
    "        #print(out.shape)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        #print(out.shape)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return F.log_softmax(out)\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "def check_accuracy(loader, model):\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            #print(data)\n",
    "            #print()\n",
    "            x = data['image'].float()\n",
    "            #print(x)\n",
    "            #print()\n",
    "            x= x.to(device=device, dtype=torch.float)  # move to device, e.g. GPU\n",
    "            #print(\"BUG\")\n",
    "            #print(data['labels'])\n",
    "            y = data['labels'].long()\n",
    "            y = y.view(y.numel())\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            #print(scores)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "\n",
    "def train_model(model, optimizer, criterion, device, num_epochs=1):\n",
    "    # Train the model\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, x in enumerate(train_loader):\n",
    "            model.train()\n",
    "            if i == 0:\n",
    "                print(x)\n",
    "            images = x['image'].float()\n",
    "            labels= x['labels'].long()\n",
    "            labels = labels.view(labels.numel())\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            #print(labels)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 50 == 49:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                #check_accuracy(validation_loader, model)\n",
    "                running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 3\n",
    "num_classes = 2\n",
    "learning_rate = 0.00001\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "model.apply(init_weights)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_model(model, optimizer, criterion, device, num_epochs)\n",
    "\n",
    "check_accuracy(validation_loader, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
